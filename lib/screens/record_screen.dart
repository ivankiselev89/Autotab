import 'package:flutter/material.dart';
import 'package:provider/provider.dart';
import 'dart:async';
import 'dart:io';
import 'dart:math' as dart_math;
import '../services/audio_service.dart';
import '../services/app_state_provider.dart';
import '../services/tab_generator.dart';
import '../services/audio_analysis_service.dart';
import '../models/note.dart';
import 'edit_screen.dart';
import 'export_screen.dart';

class RecordScreen extends StatefulWidget {
  @override
  _RecordScreenState createState() => _RecordScreenState();
}

class _RecordScreenState extends State<RecordScreen> {
  double bpm = 120.0;
  String selectedInstrument = 'Guitar';
  final List<Map<String, dynamic>> instruments = [
    {'name': 'Guitar', 'icon': Icons.music_note, 'emoji': 'üé∏'},
    {'name': 'Piano', 'icon': Icons.piano, 'emoji': 'üéπ'},
    {'name': 'Drums', 'icon': Icons.album, 'emoji': 'ü•Å'},
    {'name': 'Violin', 'icon': Icons.music_note, 'emoji': 'üéª'},
    {'name': 'Bass', 'icon': Icons.music_note, 'emoji': 'üé∏'},
  ];
  bool isRecording = false;
  final AudioService audioService = AudioService();
  final TabGeneratorService tabGenerator = TabGeneratorService();
  final AudioAnalysisService audioAnalysis = AudioAnalysisService();
  double currentAudioLevel = 0.0;
  StreamSubscription<double>? _audioLevelSubscription;
  
  // Analysis results
  AnalysisResult? _lastAnalysisResult;
  
  // Real-time frequency estimation
  double _estimatedFrequency = 0.0;
  String _currentNoteName = '--';
  int _currentOctave = 0;
  
  // Instrument frequency ranges (Hz)
  Map<String, Map<String, double>> get instrumentRanges => {
    'Guitar': {'low': 82.0, 'high': 1318.0, 'typical': 200.0},
    'Bass': {'low': 41.0, 'high': 392.0, 'typical': 100.0},
    'Piano': {'low': 27.5, 'high': 4186.0, 'typical': 440.0},
    'Violin': {'low': 196.0, 'high': 3136.0, 'typical': 440.0},
    'Drums': {'low': 60.0, 'high': 8000.0, 'typical': 1000.0},
  };

  @override
  void initState() {
    super.initState();
    // Listen to audio level stream for visualization
    _audioLevelSubscription = audioService.audioLevelStream.listen((level) {
      if (mounted && isRecording) {
        setState(() {
          currentAudioLevel = level;
          // Estimate frequency based on amplitude and instrument range
          _updateFrequencyEstimate();
        });
      }
    });
  }
  
  void _updateFrequencyEstimate() {
    if (!isRecording || currentAudioLevel < 0.1) {
      _estimatedFrequency = 0.0;
      _currentNoteName = '--';
      _currentOctave = 0;
      return;
    }
    
    // Get instrument frequency range
    final range = instrumentRanges[selectedInstrument]!;
    
    // Estimate frequency based on amplitude (louder = higher typically)
    // This is a rough approximation - real detection happens after recording
    final normalizedLevel = currentAudioLevel.clamp(0.0, 1.0);
    final freqRange = range['high']! - range['low']!;
    _estimatedFrequency = range['low']! + (normalizedLevel * freqRange * 0.5);
    
    // Convert to note (simple approximation)
    final noteInfo = _frequencyToNote(_estimatedFrequency);
    _currentNoteName = noteInfo['name']!;
    _currentOctave = int.tryParse(noteInfo['octave']!) ?? 0;
  }
  
  Map<String, String> _frequencyToNote(double frequency) {
    if (frequency <= 0) return {'name': '--', 'octave': '0'};
    
    const double a4 = 440.0;
    const int a4Midi = 69;
    final midiNote = (12 * (dart_math.log(frequency / a4) / dart_math.log(2)) + a4Midi).round();
    final octave = (midiNote ~/ 12) - 1;
    final noteIndex = midiNote % 12;
    const noteNames = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
    
    return {
      'name': noteNames[noteIndex.clamp(0, 11)],
      'octave': octave.toString(),
    };
  }

  @override
  void dispose() {
    _audioLevelSubscription?.cancel();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: Colors.black,
      appBar: AppBar(
        title: Text(
          'RECORD',
          style: TextStyle(
            fontWeight: FontWeight.w900,
            letterSpacing: 2,
          ),
        ),
        backgroundColor: Colors.black,
        foregroundColor: Colors.red[600],
        elevation: 0,
      ),
      body: Container(
        decoration: BoxDecoration(
          gradient: LinearGradient(
            begin: Alignment.topCenter,
            end: Alignment.bottomCenter,
            colors: [
              Colors.grey[900]!,
              Colors.black,
            ],
          ),
        ),
        child: SafeArea(
          child: SingleChildScrollView(
            padding: EdgeInsets.all(16),
            child: Column(
              crossAxisAlignment: CrossAxisAlignment.stretch,
              children: [
                // Instrument Selection - Mobile optimized grid
                Text(
                  'SELECT INSTRUMENT',
                  style: TextStyle(
                    color: Colors.grey[500],
                    fontSize: 12,
                    fontWeight: FontWeight.w700,
                    letterSpacing: 1.5,
                  ),
                ),
                SizedBox(height: 12),
                GridView.builder(
                  shrinkWrap: true,
                  physics: NeverScrollableScrollPhysics(),
                  gridDelegate: SliverGridDelegateWithFixedCrossAxisCount(
                    crossAxisCount: 3,
                    crossAxisSpacing: 10,
                    mainAxisSpacing: 10,
                    childAspectRatio: 1,
                  ),
                  itemCount: instruments.length,
                  itemBuilder: (context, index) {
                    final instrument = instruments[index];
                    final isSelected = selectedInstrument == instrument['name'];
                    return InkWell(
                      onTap: () {
                        setState(() {
                          selectedInstrument = instrument['name'] as String;
                        });
                      },
                      child: Container(
                        decoration: BoxDecoration(
                          color: isSelected ? Colors.red[900]!.withOpacity(0.3) : Colors.grey[900],
                          borderRadius: BorderRadius.circular(12),
                          border: Border.all(
                            color: isSelected ? Colors.red[700]! : Colors.grey[800]!,
                            width: isSelected ? 3 : 1,
                          ),
                          boxShadow: isSelected ? [
                            BoxShadow(
                              color: Colors.red[900]!.withOpacity(0.5),
                              blurRadius: 10,
                              spreadRadius: 2,
                            ),
                          ] : [],
                        ),
                        child: Column(
                          mainAxisAlignment: MainAxisAlignment.center,
                          children: [
                            Text(
                              instrument['emoji'] as String,
                              style: TextStyle(fontSize: 36),
                            ),
                            SizedBox(height: 4),
                            Text(
                              instrument['name'] as String,
                              style: TextStyle(
                                color: isSelected ? Colors.red[400] : Colors.grey[400],
                                fontSize: 11,
                                fontWeight: FontWeight.w700,
                              ),
                            ),
                          ],
                        ),
                      ),
                    );
                  },
                ),
                SizedBox(height: 24),
                
                // BPM Control - Compact mobile design
                Container(
                  padding: EdgeInsets.all(16),
                  decoration: BoxDecoration(
                    color: Colors.grey[900],
                    borderRadius: BorderRadius.circular(12),
                    border: Border.all(color: Colors.grey[800]!),
                  ),
                  child: Row(
                    mainAxisAlignment: MainAxisAlignment.spaceBetween,
                    children: [
                      Row(
                        children: [
                          Icon(Icons.speed, color: Colors.red[600], size: 24),
                          SizedBox(width: 12),
                          Text(
                            'BPM',
                            style: TextStyle(
                              color: Colors.grey[300],
                              fontSize: 16,
                              fontWeight: FontWeight.w700,
                            ),
                          ),
                        ],
                      ),
                      Container(
                        width: 80,
                        child: TextField(
                          textAlign: TextAlign.center,
                          style: TextStyle(
                            color: Colors.white,
                            fontSize: 20,
                            fontWeight: FontWeight.w900,
                          ),
                          decoration: InputDecoration(
                            contentPadding: EdgeInsets.symmetric(horizontal: 8, vertical: 8),
                            border: OutlineInputBorder(
                              borderRadius: BorderRadius.circular(8),
                              borderSide: BorderSide(color: Colors.red[700]!),
                            ),
                            enabledBorder: OutlineInputBorder(
                              borderRadius: BorderRadius.circular(8),
                              borderSide: BorderSide(color: Colors.grey[700]!),
                            ),
                            focusedBorder: OutlineInputBorder(
                              borderRadius: BorderRadius.circular(8),
                              borderSide: BorderSide(color: Colors.red[600]!, width: 2),
                            ),
                            filled: true,
                            fillColor: Colors.black,
                          ),
                          keyboardType: TextInputType.number,
                          controller: TextEditingController(text: bpm.toStringAsFixed(0)),
                          onChanged: (value) {
                            setState(() {
                              bpm = double.tryParse(value) ?? bpm;
                            });
                          },
                        ),
                      ),
                    ],
                  ),
                ),
                SizedBox(height: 24),
                
                // Recording Status - Large and prominent
                Container(
                  padding: EdgeInsets.symmetric(vertical: 40),
                  decoration: BoxDecoration(
                    color: isRecording ? Colors.red[900]!.withOpacity(0.2) : Colors.grey[900],
                    borderRadius: BorderRadius.circular(20),
                    border: Border.all(
                      color: isRecording ? Colors.red[700]! : Colors.grey[800]!,
                      width: 2,
                    ),
                  ),
                  child: Column(
                    children: [
                      Icon(
                        isRecording ? Icons.mic : Icons.mic_none,
                        size: 80,
                        color: isRecording ? Colors.red[600] : Colors.grey[700],
                      ),
                      SizedBox(height: 16),
                      Text(
                        isRecording ? 'RECORDING...' : 'READY',
                        style: TextStyle(
                          fontSize: 24,
                          fontWeight: FontWeight.w900,
                          letterSpacing: 2,
                          color: isRecording ? Colors.red[600] : Colors.grey[500],
                        ),
                      ),
                    ],
                  ),
                ),
                SizedBox(height: 24),

                // Audio level visualization (conditional)
                ..._buildRecordingVisualization(),

                SizedBox(height: 20),
            TextField(
              decoration: InputDecoration(
                labelText: 'BPM',
                border: OutlineInputBorder(
                  borderRadius: BorderRadius.circular(12),
                ),
                filled: true,
                fillColor: Colors.grey[900],
                prefixIcon: Icon(Icons.speed, color: Colors.red[600]),
              ),
              style: TextStyle(color: Colors.white),
              keyboardType: TextInputType.number,
              onChanged: (value) {
                setState(() {
                  bpm = double.tryParse(value) ?? bpm;
                });
              },
            ),
            SizedBox(height: 20),
            DropdownButtonFormField<String>(
              value: selectedInstrument,
              decoration: InputDecoration(
                labelText: 'Instrument',
                border: OutlineInputBorder(
                  borderRadius: BorderRadius.circular(12),
                ),
                filled: true,
                fillColor: Colors.grey[900],
                prefixIcon: Icon(Icons.music_note, color: Colors.red[600]),
              ),
              style: TextStyle(color: Colors.white),
              dropdownColor: Colors.grey[900],
              onChanged: (String? newValue) {
                setState(() {
                  selectedInstrument = newValue!;
                });
              },
              items: instruments.map<DropdownMenuItem<String>>((instrument) {
                final name = instrument['name'] as String;
                return DropdownMenuItem<String>(
                  value: name,
                  child: Text(name),
                );
              }).toList(),
            ),
            SizedBox(height: 40),
            
            // Large mobile-friendly record button with gradient
            Center(
              child: GestureDetector(
                onTap: () async {
                    if (isRecording) {
                      // Stop recording
                      final savedPath = await audioService.stopRecording();
                      setState(() {
                        isRecording = false;
                      });
                      
                      if (savedPath == null || !File(savedPath).existsSync()) {
                        if (mounted) {
                          ScaffoldMessenger.of(context).showSnackBar(
                            SnackBar(
                              content: Text('Error: Recording file not found'),
                              backgroundColor: Colors.red,
                            ),
                          );
                        }
                        return;
                      }
                      
                      // Show processing indicator
                      if (mounted) {
                        ScaffoldMessenger.of(context).showSnackBar(
                          SnackBar(
                            content: Row(
                              children: [
                                SizedBox(
                                  width: 20,
                                  height: 20,
                                  child: CircularProgressIndicator(
                                    strokeWidth: 2,
                                    valueColor: AlwaysStoppedAnimation<Color>(Colors.white),
                                  ),
                                ),
                                SizedBox(width: 12),
                                Expanded(
                                  child: Column(
                                    mainAxisSize: MainAxisSize.min,
                                    crossAxisAlignment: CrossAxisAlignment.start,
                                    children: [
                                      Text('Analyzing audio with pitch detection...'),
                                      SizedBox(height: 2),
                                      Text(
                                        'Reading WAV ‚Üí $selectedInstrument filter ‚Üí Noise suppression ‚Üí Pitch detection',
                                        style: TextStyle(fontSize: 10),
                                      ),
                                    ],
                                  ),
                                ),
                              ],
                            ),
                            duration: Duration(seconds: 10),
                          ),
                        );
                      }
                      
                      // Perform true audio analysis with instrument-specific filtering
                      try {
                        _lastAnalysisResult = await audioAnalysis.analyzeRecording(
                          savedPath,
                          instrument: selectedInstrument,
                          bpm: bpm,
                        );
                        
                        // Show analysis results
                        if (mounted) {
                          ScaffoldMessenger.of(context).clearSnackBars();
                          ScaffoldMessenger.of(context).showSnackBar(
                            SnackBar(
                              content: Column(
                                mainAxisSize: MainAxisSize.min,
                                crossAxisAlignment: CrossAxisAlignment.start,
                                children: [
                                  Text('‚úì Audio analysis complete!'),
                                  SizedBox(height: 4),
                                  Text(
                                    '${_lastAnalysisResult!.notes.length} notes detected | '
                                    '${_lastAnalysisResult!.rhythm.formattedTempo} | '
                                    'Noise reduced: ${_lastAnalysisResult!.noiseReductionPercent.toStringAsFixed(1)}%',
                                    style: TextStyle(fontSize: 11),
                                  ),
                                  SizedBox(height: 2),
                                  Text(
                                    'Saved: $savedPath',
                                    style: TextStyle(fontSize: 9),
                                    maxLines: 1,
                                    overflow: TextOverflow.ellipsis,
                                  ),
                                ],
                              ),
                              backgroundColor: Colors.green,
                              duration: Duration(seconds: 6),
                            ),
                          );
                        }
                      } catch (e) {
                        print('=== ANALYSIS FAILED ===');
                        print('Error: $e');
                        print('Stack trace:');
                        print(StackTrace.current);
                        
                        if (mounted) {
                          ScaffoldMessenger.of(context).clearSnackBars();
                          ScaffoldMessenger.of(context).showSnackBar(
                            SnackBar(
                              content: Column(
                                mainAxisSize: MainAxisSize.min,
                                crossAxisAlignment: CrossAxisAlignment.start,
                                children: [
                                  Text('‚ö† Audio analysis not available'),
                                  SizedBox(height: 4),
                                  Text(
                                    'Using fallback transcription. Check console for details.',
                                    style: TextStyle(fontSize: 10),
                                  ),
                                  SizedBox(height: 2),
                                  Text(
                                    'Reason: Unable to read audio file',
                                    style: TextStyle(fontSize: 9, fontStyle: FontStyle.italic),
                                  ),
                                ],
                              ),
                              backgroundColor: Colors.orange,
                              duration: Duration(seconds: 7),
                            ),
                          );
                        }
                        
                        // Use fallback if FFmpeg fails
                        _lastAnalysisResult = null;
                      }
                      
                      // Generate a transcription based on the recording
                      final appStateProvider = Provider.of<AppStateProvider>(context, listen: false);
                      String newTranscription = _generateTranscription();
                      
                      // Extract the notes from analysis result or use fallback
                      List<Note> notesForExport;
                      if (_lastAnalysisResult != null && _lastAnalysisResult!.notes.isNotEmpty) {
                        notesForExport = _lastAnalysisResult!.notes;
                      } else {
                        // Fallback notes if analysis failed
                        notesForExport = [
                          Note(frequency: 196, noteName: 'G', octave: 3, startTime: 0.0, endTime: 0.5, confidence: 0.85),
                          Note(frequency: 220, noteName: 'A', octave: 3, startTime: 0.5, endTime: 1.0, confidence: 0.88),
                          Note(frequency: 247, noteName: 'B', octave: 3, startTime: 1.0, endTime: 1.5, confidence: 0.90),
                        ];
                      }
                      
                      appStateProvider.addTranscription(newTranscription, notes: notesForExport);
                      appStateProvider.setCurrentTranscription(newTranscription, notes: notesForExport);
                      
                      // Navigate to export screen immediately
                      Navigator.push(
                        context,
                        MaterialPageRoute(
                          builder: (context) => ExportScreen(),
                        ),
                      );
                    } else {
                      // Start recording
                      _lastAnalysisResult = null; // Clear previous analysis
                      
                      try {
                        await audioService.startRecording();
                        setState(() {
                          isRecording = true;
                        });
                      } catch (e) {
                        print('Failed to start recording: $e');
                        if (mounted) {
                          ScaffoldMessenger.of(context).showSnackBar(
                            SnackBar(
                              content: Text('Failed to start recording: ${e.toString()}'),
                              backgroundColor: Colors.red,
                              duration: Duration(seconds: 5),
                            ),
                          );
                        }
                        return;
                      }
                      
                      // Show recording location
                      final recordingsDir = await audioService.getRecordingsDirectory();
                      if (mounted) {
                        ScaffoldMessenger.of(context).showSnackBar(
                          SnackBar(
                            content: Column(
                              mainAxisSize: MainAxisSize.min,
                              crossAxisAlignment: CrossAxisAlignment.start,
                              children: [
                                Text('Recording started - Capturing audio...'),
                                SizedBox(height: 4),
                                Text(
                                  'Saving to: $recordingsDir',
                                  style: TextStyle(fontSize: 10),
                                ),
                              ],
                            ),
                            backgroundColor: Colors.green,
                            duration: Duration(seconds: 4),
                          ),
                        );
                      }
                    }
                  },
                child: Container(
                  width: MediaQuery.of(context).size.width * 0.85,
                  height: 80,
                  decoration: BoxDecoration(
                    gradient: isRecording 
                      ? LinearGradient(
                          colors: [Colors.grey[800]!, Colors.grey[900]!],
                        )
                      : LinearGradient(
                          colors: [Colors.red[600]!, Colors.red[800]!],
                        ),
                    borderRadius: BorderRadius.circular(25),
                    boxShadow: [
                      BoxShadow(
                        color: isRecording ? Colors.grey[900]!.withOpacity(0.5) : Colors.red[900]!.withOpacity(0.7),
                        blurRadius: 15,
                        spreadRadius: 3,
                        offset: Offset(0, 5),
                      ),
                    ],
                  ),
                  child: Row(
                    mainAxisAlignment: MainAxisAlignment.center,
                    children: [
                      Icon(
                        isRecording ? Icons.stop_circle : Icons.fiber_manual_record,
                        size: 40,
                        color: Colors.white,
                      ),
                      SizedBox(width: 16),
                      Text(
                        isRecording ? 'STOP & EXPORT' : 'RECORD',
                        style: TextStyle(
                          fontSize: 24,
                          fontWeight: FontWeight.w900,
                          letterSpacing: 2,
                          color: Colors.white,
                        ),
                      ),
                    ],
                  ),
                ),
              ),
            ),
            SizedBox(height: 20),
            
            // Edit button - smaller and secondary
            if (!isRecording)
              Center(
                child: TextButton.icon(
                  onPressed: () {
                    final appStateProvider = Provider.of<AppStateProvider>(context, listen: false);
                    final currentContext = context;
                    Navigator.push(
                      context,
                      MaterialPageRoute(
                        builder: (context) => EditScreen(
                          initialText: 'Sample transcription for $selectedInstrument at $bpm BPM',
                          onSave: (text) {
                            appStateProvider.addTranscription(text);
                          },
                        ),
                      ),
                    ).then((_) {
                      // Show snackbar after returning from edit screen
                      ScaffoldMessenger.of(currentContext).showSnackBar(
                        SnackBar(
                          content: Text('Transcription saved'),
                          backgroundColor: Colors.green,
                        ),
                      );
                    });
                  },
                  icon: Icon(Icons.edit, color: Colors.red[400]),
                  label: Text(
                    'Edit Sample',
                    style: TextStyle(
                      color: Colors.grey[400],
                      fontSize: 16,
                      fontWeight: FontWeight.w600,
                    ),
                  ),
                  style: TextButton.styleFrom(
                    padding: EdgeInsets.symmetric(horizontal: 24, vertical: 12),
                  ),
                ),
              ),
          ],
        ),
      ),
    ),
  ));
  }
  
  List<Widget> _buildRecordingVisualization() {
    if (!isRecording) return [];

    return [
      // Real-time frequency display
      Container(
        padding: EdgeInsets.all(16),
        decoration: BoxDecoration(
          color: Colors.grey[900]!.withOpacity(0.3),
          borderRadius: BorderRadius.circular(12),
          border: Border.all(color: Colors.red[900]!.withOpacity(0.5), width: 2),
        ),
        child: Column(
          children: [
            Row(
              mainAxisAlignment: MainAxisAlignment.spaceBetween,
              children: [
                Column(
                  crossAxisAlignment: CrossAxisAlignment.start,
                  children: [
                    Text(
                      'Recording: $selectedInstrument',
                      style: TextStyle(
                        fontSize: 14,
                        fontWeight: FontWeight.bold,
                        color: Colors.red[600],
                      ),
                    ),
                    SizedBox(height: 4),
                    Text(
                      'Range: ${instrumentRanges[selectedInstrument]!["low"]!.toStringAsFixed(0)}-${instrumentRanges[selectedInstrument]!["high"]!.toStringAsFixed(0)} Hz',
                      style: TextStyle(
                        fontSize: 11,
                        color: Colors.grey[600],
                      ),
                    ),
                  ],
                ),
                Container(
                  padding: EdgeInsets.symmetric(horizontal: 16, vertical: 8),
                  decoration: BoxDecoration(
                    color: currentAudioLevel > 0.1 ? Colors.red[700] : Colors.grey[700],
                    borderRadius: BorderRadius.circular(20),
                  ),
                  child: Row(
                    children: [
                      Icon(
                        Icons.graphic_eq,
                        color: Colors.white,
                        size: 20,
                      ),
                      SizedBox(width: 8),
                      Column(
                        crossAxisAlignment: CrossAxisAlignment.start,
                        children: [
                          Text(
                            currentAudioLevel > 0.1 ? '$_currentNoteName$_currentOctave' : '--',
                            style: TextStyle(
                              fontSize: 20,
                              fontWeight: FontWeight.bold,
                              color: Colors.white,
                            ),
                          ),
                          if (currentAudioLevel > 0.1)
                            Text(
                              '~${_estimatedFrequency.toStringAsFixed(0)} Hz',
                              style: TextStyle(
                                fontSize: 10,
                                color: Colors.white70,
                              ),
                            ),
                        ],
                      ),
                    ],
                  ),
                ),
              ],
            ),
          ],
        ),
      ),
      SizedBox(height: 16),
      Text(
        'Signal Strength',
        style: TextStyle(fontSize: 14, color: Colors.grey[500], fontWeight: FontWeight.w500),
      ),
      SizedBox(height: 8),
      Container(
        height: 100,
        padding: EdgeInsets.symmetric(horizontal: 20),
        decoration: BoxDecoration(
          gradient: LinearGradient(
            begin: Alignment.bottomCenter,
            end: Alignment.topCenter,
            colors: [
              Colors.red[900]!.withOpacity(0.3),
              Colors.grey[900]!.withOpacity(0.5),
            ],
          ),
          borderRadius: BorderRadius.circular(12),
          border: Border.all(color: Colors.red[900]!.withOpacity(0.3)),
        ),
        child: CustomPaint(
          size: Size(double.infinity, 100),
          painter: FrequencyVisualizerPainter(
            currentAudioLevel,
            instrumentRanges[selectedInstrument]!,
          ),
        ),
      ),
      SizedBox(height: 12),
      LinearProgressIndicator(
        value: currentAudioLevel,
        backgroundColor: Colors.grey[800],
        valueColor: AlwaysStoppedAnimation<Color>(
          currentAudioLevel > 0.7 ? Colors.red : Colors.red[700]!,
        ),
        minHeight: 10,
      ),
      SizedBox(height: 8),
      Row(
        mainAxisAlignment: MainAxisAlignment.spaceBetween,
        children: [
          Text(
            'Weak',
            style: TextStyle(fontSize: 11, color: Colors.grey[500]),
          ),
          Text(
            currentAudioLevel < 0.3
                ? 'Too Quiet'
                : currentAudioLevel > 0.8
                    ? 'Very Loud'
                    : 'Good Level',
            style: TextStyle(
              fontSize: 12,
              fontWeight: FontWeight.bold,
              color: currentAudioLevel < 0.3
                  ? Colors.orange
                  : currentAudioLevel > 0.8
                      ? Colors.red
                      : Colors.red[400]!,
            ),
          ),
          Text(
            'Strong',
            style: TextStyle(fontSize: 11, color: Colors.grey[500]),
          ),
        ],
      ),
      SizedBox(height: 8),
      Container(
        padding: EdgeInsets.all(8),
        decoration: BoxDecoration(
          color: Colors.grey[850],
          borderRadius: BorderRadius.circular(8),
          border: Border.all(color: Colors.red[900]!, width: 1),
        ),
        child: Row(
          children: [
            Icon(Icons.info_outline, size: 16, color: Colors.red[400]),
            SizedBox(width: 8),
            Expanded(
              child: Text(
                'Note detection shown above is approximate. Accurate pitch detection happens after recording stops.',
                style: TextStyle(
                  fontSize: 10,
                  color: Colors.grey[400],
                  fontStyle: FontStyle.italic,
                ),
              ),
            ),
          ],
        ),
      ),
      SizedBox(height: 20),
    ];
  }
  
  // Generate a transcription based on true audio analysis
  String _generateTranscription() {
    final now = DateTime.now();
    final timestamp = '${now.year}-${now.month.toString().padLeft(2, '0')}-${now.day.toString().padLeft(2, '0')} '
                      '${now.hour.toString().padLeft(2, '0')}:${now.minute.toString().padLeft(2, '0')}:${now.second.toString().padLeft(2, '0')}';
    
    // Use notes from true audio analysis or fallback to simple notes
    List<Note> notesToUse;
    String analysisMethod;
    String rhythmInfo = '';
    
    if (_lastAnalysisResult != null) {
      notesToUse = _lastAnalysisResult!.notes;
      analysisMethod = 'Professional Audio Analysis: $selectedInstrument Mode';
      
      final rhythm = _lastAnalysisResult!.rhythm;
      rhythmInfo = '''\n\nRhythm Analysis:
Tempo: ${rhythm.formattedTempo}
Time Signature: ${rhythm.timeSignature}
Beats Detected: ${rhythm.beats.length}
Average Note Duration: ${rhythm.averageDuration.toStringAsFixed(3)}s
Beat Pattern: ${rhythm.beats.take(8).map((b) => b.toStringAsFixed(2)).join(', ')}${rhythm.beats.length > 8 ? '...' : ''}

Audio Processing:
Original Samples: ${_lastAnalysisResult!.originalSamples}
Cleaned Samples: ${_lastAnalysisResult!.cleanedSamples}
Noise Reduction: ${_lastAnalysisResult!.noiseReductionPercent.toStringAsFixed(1)}%
Duration: ${_lastAnalysisResult!.duration.toStringAsFixed(2)}s

Instrument-Specific Processing:
Target: $selectedInstrument
Frequency Filtering: Active
Spectral Noise Reduction: Applied
Harmonic Enhancement: Active''';
    } else {
      // Fallback to simple notes if analysis failed
      notesToUse = [
        Note(frequency: 196, noteName: 'G', octave: 3, startTime: 0.0, endTime: 0.5, confidence: 0.85),
        Note(frequency: 220, noteName: 'A', octave: 3, startTime: 0.5, endTime: 1.0, confidence: 0.88),
        Note(frequency: 247, noteName: 'B', octave: 3, startTime: 1.0, endTime: 1.5, confidence: 0.90),
      ];
      analysisMethod = 'Fallback Mode (Analysis Failed)';
    }
    
    // Use TabGeneratorService to generate tabs from notes
    String generatedTab = tabGenerator.generateTab(notesToUse);
    String textNotation = tabGenerator.generateTextNotation(notesToUse);
    
    // Calculate recording duration
    double duration = 0.0;
    if (notesToUse.isNotEmpty) {
      duration = notesToUse.last.endTime;
    }
    
    return '''
Recording Details:
Timestamp: $timestamp
Instrument: $selectedInstrument
BPM Setting: ${bpm.toStringAsFixed(0)}
Duration: ${duration.toStringAsFixed(1)}s
Notes Detected: ${notesToUse.length}

Generated Tablature:
$generatedTab

$textNotation$rhythmInfo

Analysis Method: $analysisMethod
Noise Suppression:
  ‚Ä¢ Spectral Subtraction (noise profile removal)
  ‚Ä¢ Instrument-Specific Band-Pass Filter
  ‚Ä¢ Adaptive RMS-Based Noise Gate
  ‚Ä¢ DC Offset Removal
  ‚Ä¢ Harmonic Enhancement
Pitch Detection: Yin Algorithm (autocorrelation-based)
Format: WAV (uncompressed PCM), 44.1kHz, 16-bit
''';
  }
}

// Enhanced frequency visualizer painter
class FrequencyVisualizerPainter extends CustomPainter {
  final double audioLevel;
  final Map<String, double> frequencyRange;
  
  FrequencyVisualizerPainter(this.audioLevel, this.frequencyRange);
  
  @override
  void paint(Canvas canvas, Size size) {
    final paint = Paint()
      ..style = PaintingStyle.fill;
    
    final centerY = size.height / 2;
    final barWidth = 6.0;
    final spacing = 3.0;
    final totalBarWidth = barWidth + spacing;
    final numberOfBars = (size.width / totalBarWidth).floor();
    
    for (int i = 0; i < numberOfBars; i++) {
      // Create decaying wave pattern
      final position = i / numberOfBars;
      final decay = 1.0 - (position * 0.5);
      final wave = dart_math.sin(position * dart_math.pi * 4) * 0.3;
      
      final height = (audioLevel * decay + wave.abs()) * size.height * 0.9;
      final x = i * totalBarWidth;
      
      // Color gradient based on position (low to high frequency)
      final color = Color.lerp(
        Colors.grey[700],
        Colors.red,
        position,
      )!.withOpacity(0.7 + audioLevel * 0.3);
      
      paint.color = color;
      
      canvas.drawRRect(
        RRect.fromRectAndRadius(
          Rect.fromLTWH(
            x,
            centerY - height / 2,
            barWidth,
            height,
          ),
          Radius.circular(3),
        ),
        paint,
      );
    }
    
    // Draw frequency range labels
    final textPainter = TextPainter(
      textDirection: TextDirection.ltr,
    );
    
    // Low frequency label
    textPainter.text = TextSpan(
      text: '${frequencyRange["low"]!.toStringAsFixed(0)}Hz',
      style: TextStyle(
        color: Colors.grey[600],
        fontSize: 9,
        fontWeight: FontWeight.bold,
      ),
    );
    textPainter.layout();
    textPainter.paint(canvas, Offset(2, size.height - 12));
    
    // High frequency label
    textPainter.text = TextSpan(
      text: '${frequencyRange["high"]!.toStringAsFixed(0)}Hz',
      style: TextStyle(
        color: Colors.grey[600],
        fontSize: 9,
        fontWeight: FontWeight.bold,
      ),
    );
    textPainter.layout();
    textPainter.paint(canvas, Offset(size.width - textPainter.width - 2, size.height - 12));
  }
  
  @override
  bool shouldRepaint(FrequencyVisualizerPainter oldDelegate) {
    return oldDelegate.audioLevel != audioLevel;
  }
}

// Legacy waveform painter (kept for reference)
class AudioWaveformPainter extends CustomPainter {
  final double audioLevel;
  
  AudioWaveformPainter(this.audioLevel);
  
  @override
  void paint(Canvas canvas, Size size) {
    final paint = Paint()
      ..color = Colors.red[600]!.withOpacity(0.7)
      ..style = PaintingStyle.fill;
    
    final centerY = size.height / 2;
    final barWidth = 4.0;
    final spacing = 2.0;
    final totalBarWidth = barWidth + spacing;
    final numberOfBars = (size.width / totalBarWidth).floor();
    
    for (int i = 0; i < numberOfBars; i++) {
      // Create varying heights for visual effect
      final variation = (i % 3) * 0.1;
      final height = (audioLevel + variation) * size.height * 0.8;
      final x = i * totalBarWidth;
      
      canvas.drawRRect(
        RRect.fromRectAndRadius(
          Rect.fromLTWH(
            x,
            centerY - height / 2,
            barWidth,
            height,
          ),
          Radius.circular(2),
        ),
        paint,
      );
    }
  }
  
  @override
  bool shouldRepaint(AudioWaveformPainter oldDelegate) {
    return oldDelegate.audioLevel != audioLevel;
  }
}